# adapted GA workflow from https://github.com/stackhpc/s3-active-storage-rs
---
name: S3 Test Connect

on:
  push:
    branches:
      - main
      - add_s3_tests
  schedule:
    - cron: '0 0 * * *'  # nightly

jobs:
  linux-test:
    runs-on: "ubuntu-latest"
    strategy:
      matrix:
        python-version: ["3.9", "3.10", "3.11"]
      fail-fast: false
    name: Linux Python ${{ matrix.python-version }}
    steps:
      - uses: actions/checkout@v3
        with:
          fetch-depth: 0
      - uses: conda-incubator/setup-miniconda@v2
        with:
          activate-environment: activestorage
          environment-file: environment.yml
          python-version: ${{ matrix.python-version }}
          miniforge-version: "latest"
          miniforge-variant: Mambaforge
          use-mamba: true
      - shell: bash -l {0}
        run: conda --version
      - shell: bash -l {0}
        run: python -V

      - name: Configure compliance test suite
        run: |
          echo 'PROXY_URL = "http://localhost:8080"' >> config.py

      - name: Start minio object storage
        run: |
          s3_scripts/minio-start

      - name: Wait for minio object storage to start
        run: |
          until curl -if http://localhost:9001; do
            sleep 1;
          done

      - name: Run container
        run: docker run -it --detach --rm --net=host --name s3-active-storage ghcr.io/stackhpc/s3-active-storage-rs:latest

      - uses: actions/checkout@v3
        with:
          fetch-depth: 0
      - uses: conda-incubator/setup-miniconda@v2
        with:
          activate-environment: activestorage-minio
          environment-file: environment.yml
          python-version: ${{ matrix.python-version }}
          miniforge-version: "latest"
          miniforge-variant: Mambaforge
          use-mamba: true
      - name: Put data in AWS bucket
        shell: bash -l {0}
        run: |
          aws s3 mb s3://pyactivestorage-17666C4471777760
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          AWS_DEFAULT_REGION: 'eu-west-1'
      - name: Get PyActiveStorage and run tests
        shell: bash -l {0}
        # this bit here runs the full s3 shortcut of PyActiveStorage
        # at the mo does it all but hits AWS error - no bucket (duh!)
        run: |
          conda --version
          python -V
          which python
          pip install -e .
          pytest

      - name: Stop minio object storage
        run: s3_scripts/minio-stop
        if: always()
